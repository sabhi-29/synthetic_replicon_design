{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5bb85-4c2e-46a5-984d-09c870bca6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel notebook to addgene replication extraction blast removing features allison told to do so\n",
    "\n",
    "# to extact from uniprot -> molecular function and biological process for cds of protein sequences obtained after blastx search. \n",
    "# In blastx search for the cds we take the top ten search result desciption, for their corresponding protein sequence get the information mentioned above from uniprot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f11b69a-cf6c-454e-a7b7-e2a41167290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bef21c-5d87-4427-a8f9-c52586e0f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"/scratch/alopatki_lab/Sharma/summer_project/db_wo_blast_uniprot.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e42fd-2488-4974-8538-999503f07522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting all cds features from full_df\n",
    "all_cds = {}\n",
    "for i in range(full_df.shape[0]):\n",
    "    print(f\"Currently processing row: {i+1}/{full_df.shape[0]}\")\n",
    "    curr_row = full_df.iloc[i]\n",
    "    if curr_row['Feature Type'] == 'CDS':\n",
    "        if curr_row[\"Feature Label\"] not in all_cds.keys():\n",
    "            all_cds[curr_row[\"Feature Label\"]] = [curr_row[\"Feature Sequence\"]]\n",
    "        else:\n",
    "            all_cds[curr_row[\"Feature Label\"]].append(curr_row[\"Feature Sequence\"])\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499b99c-1b4e-4b1c-8a11-3282278513ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open a file in binary write mode\n",
    "with open(\"/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_dict.pkl\", \"wb\") as file:\n",
    "    # Pickle the dictionary and write it to the file\n",
    "    pickle.dump(all_cds, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0437d6-3908-4c4f-8c56-8bb667698e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = list(all_cds.keys())\n",
    "# printing keys with more than one sequences\n",
    "counter = 0\n",
    "for key in all_keys:\n",
    "    val_len = len(all_cds[key])\n",
    "    if val_len > 1:\n",
    "        counter += 1\n",
    "print(all_cds[all_keys[0]])\n",
    "\n",
    "# Surprisingly 327 feature label have more than one feature sequences (Need to get through Allison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c7c41-a24c-46ac-a8d7-5efb93ee38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d7579-0a2c-432b-bc91-6d990ec0480f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing all the color keyword cds features I could find\n",
    "color_keywords = [\"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Cyan\", \"Turquoise\", \"Gold\", \n",
    "                  \"Scarlet\", \"Crimson\", \"Cerulean\", \"Wasabi\", \"Clover\", \"Plum\", \"Citrine\", \n",
    "                  \"FP\", \"mCherry\", \"mKate\", \"mRuby\", \"mCardinal\", \"mTagBFP\", \"mScarlet\", \n",
    "                  \"mEos\", \"YPet\", \"Venus\", \"mNeonGreen\", \"mTurquoise\", \"mApple\", \"pHRed\",\n",
    "                  \"mGold\", \"LSSmOrange\", \"iRFP\", \"E2-Crimson\", \"CyPet\", \"KillerOrange\", \n",
    "                  \"Dronpa-Green\", \"mEGFP\", \"Dendra\", \"mStrawberry\", \"SYFP\", \"Kusabira-Orange\",\n",
    "                  \"cp173Venus\", \"NirFP\", \"TurboRFP\", \"dTomato\", \"mOrange\", \"GCaMP\", \n",
    "                  \"mTFP\", \"TagBFP\", \"mCyRFP\", \"miRFP\", \"daGFP\", \"AmCyan\", \"Kaede\", \"EosFP\",\n",
    "                  \"mVenus\", \"QuasAr\", \"Topaz YFP\", \"CyRFP\", \"Peredox\", \"Azurite BFP\", \n",
    "                  \"CopGFP\", \"mEos4a\", \"miRFP709\", \"mKalama1\", \"mKikGR1\", \"msGFP2\",\n",
    "                  \"DsRed-Monomer\", \"miRFP670\", \"PAmKate\", \"iRFP702\", \"superecliptic pHluorin\", \n",
    "                  \"mOrange2\", \"mCarmine\", \"HcRed\", \"hGLuc\", \"mAmetrine\"]\n",
    "\n",
    "for name in all_keys:\n",
    "  for keyword in color_keywords:\n",
    "    if keyword in name:\n",
    "      print(f\"Removing feature label: {name}\")  \n",
    "      all_keys.remove(name)\n",
    "      break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609e2fd-752f-4d5d-9250-fd9020db46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will make a list of all the features Allison suggested to remove and if they are present in all_keys list we will remove them\n",
    "features_to_remove_df = pd.read_excel(\"/scratch/alopatki_lab/Sharma/summer_project/db_wo_blast_uniprot_AJLnotes.xlsm\", sheet_name = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61329acd-4f54-4a0f-8f1d-958ffcc67da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = []\n",
    "for i in range(features_to_remove_df.shape[0]):\n",
    "    curr_row = features_to_remove_df.iloc[i]\n",
    "    if curr_row[\"to_remove\"] == 'remove':\n",
    "        features_to_remove.append(curr_row[\"Feature Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f99fa-34c3-4cbb-a662-bab4f7f8ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_to_remove:\n",
    "    if feature in all_keys:\n",
    "        print(f\"Feature removed: {feature}\")\n",
    "        all_keys.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43873-70ea-4a1f-a4a1-4388e14c05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the required feature labels in the all_cds dict then, pickling it for future reference\n",
    "cds_to_keep = {}\n",
    "for key in all_keys:\n",
    "    cds_to_keep[key] = all_cds[key]\n",
    "\n",
    "\n",
    "with open(\"/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_dict_cleaned_v1.pkl\", \"wb\") as file:\n",
    "    # Pickle the dictionary and write it to the file\n",
    "    pickle.dump(cds_to_keep, file)\n",
    "\n",
    "# Final cds labels on which we'll run the blast -> only 276 such features are present (v1), 223 of them have more than one sequence in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5f4d6-5e91-4469-b1bf-b6e696b8e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will make a code that will query a gene name on uniprot, we get the go annotations for the entry which contain\n",
    "# the feaure label as a gene name in the entry. If that is not the case we return an empty result in the hopes that the blast result\n",
    "# will be more dependable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338db4a-fd70-4600-ad72-d9aefdd4ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time as time\n",
    "\n",
    "def search_uniprot_gene(gene_name):\n",
    "    \"\"\"\n",
    "    Searches for a gene name on UniProt, scrolls through results,\n",
    "    and extracts the 'Gene:' value from the top 10 results. \n",
    "    If the 'Gene:' value contains the search gene_name, clicks on the \n",
    "    corresponding link within the card.\n",
    "\n",
    "    Args:\n",
    "        gene_name (str): The name of the gene to search for.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the 'Gene:' value and a boolean\n",
    "        indicating whether the link was clicked for the top 10 results,\n",
    "        or None if an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")  # Uncomment for background\n",
    "\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://www.uniprot.org/\")\n",
    "\n",
    "        search_box = driver.find_element(By.CSS_SELECTOR, \"div.main-search__input-container > input[type='search']\")\n",
    "        search_box.send_keys(gene_name)\n",
    "\n",
    "        search_button = driver.find_element(By.CSS_SELECTOR, \"button.button.primary[type='submit']\")\n",
    "        search_button.click()\n",
    "\n",
    "        # Handle the view selection prompt\n",
    "        try:\n",
    "            view_selection_prompt = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(p, 'Select how you would like to view your results')]\"))\n",
    "            )\n",
    "            table_radio = view_selection_prompt.find_element(By.XPATH, \".//input[@type='radio']\")\n",
    "            table_radio.click()\n",
    "            view_results_button = view_selection_prompt.find_element(By.XPATH, \".//button[text()='View results']\")\n",
    "            view_results_button.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Wait for the specific <ul> element containing the results\n",
    "        result_list = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.data-list.no-bullet.hotjar-margin.Anr5j\"))\n",
    "        )\n",
    "\n",
    "        # Extract gene names and click links if applicable\n",
    "        # gene_results = []\n",
    "        cards = result_list.find_elements(By.CSS_SELECTOR, \"section.card\")\n",
    "        for card in cards[:10]:  # Process only the top 10 cards\n",
    "            try:\n",
    "                gene_parent = card.find_element(By.XPATH, \".//div[@class='card__content']//strong[text()='Gene:']/parent::div\")\n",
    "                gene_text = gene_parent.text\n",
    "                gene_value = (gene_text.split(\"Gene:\")[1].strip()).split('·')[0]\n",
    "\n",
    "                if gene_name.lower() in gene_value.lower():\n",
    "                    link = card.find_element(By.CSS_SELECTOR, \"h2.small a\")\n",
    "                    link.click()\n",
    "\n",
    "                    # Scroll to GO annotations section\n",
    "                    go_header = WebDriverWait(driver, 20).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, \"//h3[@data-article-id='gene_ontology']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", go_header)\n",
    "\n",
    "                    # Extract GO annotations table\n",
    "                    try:\n",
    "                        table_wrapper = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, \"//h3[@data-article-id='gene_ontology']/following-sibling::div[1]\"))\n",
    "                        )\n",
    "                        table = table_wrapper.find_element(By.TAG_NAME, \"table\")  # Find table within the wrapper\n",
    "                        print(table)\n",
    "                        return extract_table_data(table)  # Return the table dictionary directly\n",
    "                    except:\n",
    "                        print(\"GO annotations table not found or error extracting data.\")\n",
    "                        return None  # Return None if table not found or extraction error\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing card: {e}\")\n",
    "\n",
    "        return None  # Return None if no matching gene is found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        driver.quit() \n",
    "\n",
    "def extract_table_data(table):\n",
    "    \"\"\"\n",
    "    Extracts data from the GO annotations table element.\n",
    "\n",
    "    Args:\n",
    "        table (WebElement): The table element to extract data from.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the table data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        table_data = {}\n",
    "        rows = table.find_elements(By.XPATH, \".//tr[not(@class='pd-group-header') and not(@class='pd-group-footer')]\")  # Select all data rows\n",
    "\n",
    "        for row in rows:\n",
    "            aspect_element = row.find_element(By.XPATH, \".//td[2]\")\n",
    "            aspect = aspect_element.text.strip()\n",
    "\n",
    "            term_element = row.find_element(By.XPATH, \".//td[3]/a\")\n",
    "            term = term_element.text.strip()\n",
    "\n",
    "            if aspect in table_data:\n",
    "                table_data[aspect] += \", \" + term\n",
    "            else:\n",
    "                table_data[aspect] = term\n",
    "\n",
    "        return table_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting table data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "gene_results = search_uniprot_gene(\"trfA\")\n",
    "print(gene_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a64f96-c900-4c40-aec1-1638ad5b783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time as time\n",
    "\n",
    "def search_uniprot_gene(gene_name):\n",
    "    \"\"\"\n",
    "    Searches for a gene name on UniProt, scrolls through results,\n",
    "    and extracts the 'Gene:' value and UniProt ID from the top 10 results.\n",
    "    If the 'Gene:' value contains the search gene_name, it fetches the \n",
    "    GO annotations using the UniProt ID and the QuickGO API. \n",
    "\n",
    "    Args:\n",
    "        gene_name (str): The name of the gene to search for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the UniProt ID and its corresponding GO \n",
    "        annotations, or None if an error occurs or the gene is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")  # Uncomment for background\n",
    "\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://www.uniprot.org/\")\n",
    "\n",
    "        search_box = driver.find_element(By.CSS_SELECTOR, \"div.main-search__input-container > input[type='search']\")\n",
    "        search_box.send_keys(gene_name)\n",
    "\n",
    "        search_button = driver.find_element(By.CSS_SELECTOR, \"button.button.primary[type='submit']\")\n",
    "        search_button.click()\n",
    "\n",
    "        # Handle the view selection prompt\n",
    "        try:\n",
    "            view_selection_prompt = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(p, 'Select how you would like to view your results')]\"))\n",
    "            )\n",
    "            table_radio = view_selection_prompt.find_element(By.XPATH, \".//input[@type='radio']\")\n",
    "            table_radio.click()\n",
    "            view_results_button = view_selection_prompt.find_element(By.XPATH, \".//button[text()='View results']\")\n",
    "            view_results_button.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Wait for the specific <ul> element containing the results\n",
    "        result_list = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.data-list.no-bullet.hotjar-margin.Anr5j\"))\n",
    "        )\n",
    "\n",
    "        cards = result_list.find_elements(By.CSS_SELECTOR, \"section.card\")\n",
    "        for card in cards[:10]:\n",
    "            try:\n",
    "                gene_parent = card.find_element(By.XPATH, \".//div[@class='card__content']//strong[text()='Gene:']/parent::div\")\n",
    "                gene_text = gene_parent.text\n",
    "                gene_value = (gene_text.split(\"Gene:\")[1].strip()).split('·')[0]\n",
    "\n",
    "                if gene_name.lower() in gene_value.lower():\n",
    "                    link = card.find_element(By.CSS_SELECTOR, \"h2.small a\")\n",
    "                    uniprot_id = link.get_attribute(\"href\").split(\"/\")[-1]  # Extract UniProt ID\n",
    "                    link.click()\n",
    "                    # print(uniprot_id)\n",
    "                    # ... (No need to scroll to GO annotations section) ...\n",
    "\n",
    "                    go_annotations = get_go_annotations(uniprot_id)  # Fetch GO annotations\n",
    "                    # driver.back()  # Go back to results page\n",
    "                    return {uniprot_id: go_annotations}  # Return ID and annotations\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing card: {e}\")\n",
    "                return None\n",
    "\n",
    "        return None  # Return None if no matching gene is found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def get_go_annotations(uniprot_id):\n",
    "    \"\"\"Fetches GO annotations from QuickGO API and extracts relevant data, \n",
    "    including GO term names.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://www.ebi.ac.uk/QuickGO/services/annotation/search?geneProductId={uniprot_id}\"\n",
    "    response = requests.get(url, headers={\"Accept\": \"application/json\"})\n",
    "\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        go_terms = []\n",
    "\n",
    "        for entry in data['results']:\n",
    "            go_id = entry['goId']\n",
    "            go_name = get_go_term_name(go_id)  # Get the GO term name\n",
    "            go_terms.append({\n",
    "                'goId': go_id,\n",
    "                'goAspect': entry['goAspect'],\n",
    "                'goName': go_name\n",
    "            })\n",
    "\n",
    "        return go_terms\n",
    "    else:\n",
    "        print(f\"Error fetching data from QuickGO: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_go_term_name(go_id):\n",
    "    \"\"\"Fetches the GO term name for a given GO ID.\"\"\"\n",
    "\n",
    "    url = f\"https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/{go_id}\"\n",
    "    response = requests.get(url, headers={\"Accept\": \"application/json\"})\n",
    "\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        return data['results'][0]['name']  # Extract and return the term name\n",
    "    else:\n",
    "        print(f\"Error fetching GO term name for {go_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# gene_results = search_uniprot_gene(\"GUS\")\n",
    "# print(gene_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19930f-67ba-4209-9e31-0de2e447e55c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running this functino on all the filtered cds now\n",
    "\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "# Load the pickle file\n",
    "with open('/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_dict_cleaned_v1.pkl', 'rb') as f:\n",
    "    all_cds = pickle.load(f)\n",
    "\n",
    "cds_go_annotations = {}\n",
    "\n",
    "for i in range(len(all_cds)):\n",
    "    print(f\"Currently Processing cds: {i+1}/{len(all_cds)}\")\n",
    "    curr_cds = list(all_cds.keys())[i]\n",
    "    result = search_uniprot_gene(curr_cds)\n",
    "    print(result)\n",
    "    cds_go_annotations[curr_cds] = result\n",
    "    clear_output(wait = True)  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac6e25-c951-427d-87d7-a904cd622033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(262,len(all_cds)):\n",
    "    print(f\"Currently Processing cds: {i+1}/{len(all_cds)}\")\n",
    "    curr_cds = list(all_cds.keys())[i]\n",
    "    result = search_uniprot_gene(curr_cds)\n",
    "    print(result)\n",
    "    cds_go_annotations[curr_cds] = result\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166cafe-0dad-4e73-91c1-5778f67640f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_go_done.pkl\", \"wb\") as file:\n",
    "    # Pickle the dictionary and write it to the file\n",
    "    pickle.dump(cds_go_annotations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94163f42-57b0-4682-9a32-ade3c02c1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_go_done.pkl\", \"rb\") as file:\n",
    "    # Pickle the dictionary and write it to the file\n",
    "    cds_go_annotations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58cba13c-c656-46c5-aa7a-7e90df1457e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making oriflag column for the CDS features based on go annotations\n",
    "# First we will have to make a dictionary for the go annotations for each cds we have in cds_go_annotations\n",
    "\n",
    "cds_features = list(cds_go_annotations.keys())\n",
    "# cds_go_annotations[cds_features[0]]\n",
    "\n",
    "cds_go_annotations_dict_cleaned = {}\n",
    "for i in range(len(cds_features)):\n",
    "    curr_feature = cds_features[i]\n",
    "    go_annotations_raw = cds_go_annotations[curr_feature]\n",
    "    # print(type(go_annotations_raw))\n",
    "    cds_go_annotations_dict_cleaned[curr_feature] = None\n",
    "\n",
    "    if go_annotations_raw == None:\n",
    "        continue\n",
    "    \n",
    "    # Extracting all the biological_process and molecular_function\n",
    "\n",
    "    list_of_dicts = go_annotations_raw[list(go_annotations_raw.keys())[0]]\n",
    "    feature_dict = {}\n",
    "    for each_dict in list_of_dicts:\n",
    "        if each_dict['goAspect'] in feature_dict.keys():\n",
    "            feature_dict[each_dict['goAspect']].append(each_dict['goName'])\n",
    "        else:\n",
    "            feature_dict[each_dict['goAspect']] = [each_dict['goName']]\n",
    "\n",
    "    for each_feature in feature_dict.keys():\n",
    "        unique_val = set(feature_dict[each_feature])\n",
    "        feature_dict[each_feature] = list(unique_val)\n",
    "    \n",
    "    cds_go_annotations_dict_cleaned[curr_feature] = feature_dict\n",
    "# print(feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76c8140-066f-4e77-a8ff-29d2b35cac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "none_count = 0\n",
    "for key in cds_go_annotations_dict_cleaned.keys():\n",
    "    if cds_go_annotations_dict_cleaned[key] == None:\n",
    "        none_count += 1\n",
    "print(none_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d2493f-9ebe-40e7-8378-66ed6ff60030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_replication_related2(text):\n",
    "  \"\"\"\n",
    "  Checks if the given text is related to replication, ignoring text within brackets.\n",
    "  Improved for higher accuracy and reduced false positives.\n",
    "\n",
    "  Args:\n",
    "    text: The text to check.\n",
    "\n",
    "  Returns:\n",
    "    True if the text is related to replication, False otherwise.\n",
    "  \"\"\"\n",
    "\n",
    "  # Remove text within brackets\n",
    "  text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "  # Define specific patterns for replication-related proteins\n",
    "  patterns = [\n",
    "      r\"\\brop\\b\",  # Match \"rop\" as a whole word\n",
    "      r\"replication\\s*(?:protein|factor|initiator)?\", \n",
    "      r\"plasmid\\s*(?:replication|copy\\s*number|partition|segregation)?\",\n",
    "      r\"ori\\s*(?:region|sequence)?\",\n",
    "      r\"dnaa\\s*(?:protein)?\",\n",
    "      r\"dnab\\s*(?:helicase)?\",\n",
    "      r\"dnac\\s*(?:protein)?\",\n",
    "      r\"dna\\s*polymerase\\s*(?:i|iii)?\", \n",
    "      r\"primase\",\n",
    "      r\"replisome\",\n",
    "      r\"topoisomerase\",\n",
    "      r\"gyrase\",\n",
    "      r\"dna\\s*binding\\s*protein\\s*(?:involved\\s*in\\s*replication)?\",\n",
    "  ]\n",
    "\n",
    "  # Check for matches with the specific patterns\n",
    "  if any(re.search(pattern, text, re.IGNORECASE) for pattern in patterns):\n",
    "    return True\n",
    "\n",
    "  # Additional check for terms that might indicate replication but require context\n",
    "  # These terms are more likely to be false positives on their own\n",
    "  potential_terms = [\"conjugation\", \"transformation\", \"transduction\"]\n",
    "  for term in potential_terms:\n",
    "    if re.search(term, text, re.IGNORECASE):\n",
    "      # Add more specific checks based on your domain knowledge\n",
    "      # For example, check if the term is near other replication-related words\n",
    "      if \"plasmid\" in text.lower() or \"dna\" in text.lower():\n",
    "        return True\n",
    "\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5072bc2-9ea3-434a-93a3-f4b879cee81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Go Annotations\"] = None\n",
    "full_df[\"Ori Flag\"] = 0\n",
    "for i in range(full_df.shape[0]):\n",
    "    curr_row = full_df.iloc[i]\n",
    "\n",
    "    if curr_row[\"Feature Type\"] == \"rep_origin\" or curr_row[\"Feature Type\"] == \"oriT\":\n",
    "        full_df.at[i, 'Ori Flag'] = 1\n",
    "    if curr_row[\"Feature Type\"] == \"CDS\":\n",
    "        if curr_row[\"Feature Label\"] in cds_go_annotations_dict_cleaned.keys():\n",
    "            full_df.at[i, \"Go Annotations\"] = cds_go_annotations_dict_cleaned[curr_row[\"Feature Label\"]]\n",
    "            all_go_annotations = []\n",
    "            if cds_go_annotations_dict_cleaned[curr_row[\"Feature Label\"]] != None:\n",
    "                for key in cds_go_annotations_dict_cleaned[curr_row[\"Feature Label\"]].keys():\n",
    "                    all_go_annotations = [x for x in cds_go_annotations_dict_cleaned[curr_row[\"Feature Label\"]][key]]\n",
    "                    \n",
    "                \n",
    "                for things in all_go_annotations:\n",
    "                    if is_replication_related2(things):\n",
    "                        full_df.at[i, 'Ori Flag'] = 1\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede30940-ad6d-4db8-8218-0a8c2e5b1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"/scratch/alopatki_lab/Sharma/summer_project/db_uniprot_only_oriflag.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d38e48e9-7a13-4da1-840a-8e89cd60b475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q07327': [{'goId': 'GO:0000149',\n",
       "   'goAspect': 'molecular_function',\n",
       "   'goName': 'SNARE binding'},\n",
       "  {'goId': 'GO:0019905',\n",
       "   'goAspect': 'molecular_function',\n",
       "   'goName': 'syntaxin binding'},\n",
       "  {'goId': 'GO:0006886',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'intracellular protein transport'},\n",
       "  {'goId': 'GO:0006887',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'exocytosis'},\n",
       "  {'goId': 'GO:0006904',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'vesicle docking involved in exocytosis'},\n",
       "  {'goId': 'GO:0007268',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'chemical synaptic transmission'},\n",
       "  {'goId': 'GO:0007268',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'chemical synaptic transmission'},\n",
       "  {'goId': 'GO:0007269',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'neurotransmitter secretion'},\n",
       "  {'goId': 'GO:0007269',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'neurotransmitter secretion'},\n",
       "  {'goId': 'GO:0007269',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'neurotransmitter secretion'},\n",
       "  {'goId': 'GO:0007269',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'neurotransmitter secretion'},\n",
       "  {'goId': 'GO:0007317',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'regulation of pole plasm oskar mRNA localization'},\n",
       "  {'goId': 'GO:0009416',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'response to light stimulus'},\n",
       "  {'goId': 'GO:0015031',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'protein transport'},\n",
       "  {'goId': 'GO:0016082',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'synaptic vesicle priming'},\n",
       "  {'goId': 'GO:0016192',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'vesicle-mediated transport'},\n",
       "  {'goId': 'GO:0016192',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'vesicle-mediated transport'},\n",
       "  {'goId': 'GO:0016192',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'vesicle-mediated transport'},\n",
       "  {'goId': 'GO:0030707',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'follicle cell of egg chamber development'},\n",
       "  {'goId': 'GO:0032940',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'secretion by cell'},\n",
       "  {'goId': 'GO:0048489',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'synaptic vesicle transport'},\n",
       "  {'goId': 'GO:1900006',\n",
       "   'goAspect': 'biological_process',\n",
       "   'goName': 'positive regulation of dendrite development'},\n",
       "  {'goId': 'GO:0005886',\n",
       "   'goAspect': 'cellular_component',\n",
       "   'goName': 'plasma membrane'},\n",
       "  {'goId': 'GO:0030141',\n",
       "   'goAspect': 'cellular_component',\n",
       "   'goName': 'secretory granule'},\n",
       "  {'goId': 'GO:0005737',\n",
       "   'goAspect': 'cellular_component',\n",
       "   'goName': 'cytoplasm'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds_go_annotations[cds_features[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04eb000-0ed7-44ff-9338-c0d8da6292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the result from both the dataframes into a single dataframe\n",
    "full_df = pd.read_csv(\"/scratch/alopatki_lab/Sharma/summer_project/db_uniprot_only_oriflag.csv\")\n",
    "full_df2 = pd.read_csv(\"/scratch/alopatki_lab/Sharma/summer_project/db_blast_only_oriflag.csv\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88571ff-0a29-4d81-8c39-b32b6ba3946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ashar58/tmp/ipykernel_72263/3623099466.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_combined[\"Blast Titles\"] = full_df2['Blast titles']\n",
      "/scratch/ashar58/tmp/ipykernel_72263/3623099466.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_combined['Blast Prot Seq'] = full_df2['Blast Prot Seq']\n"
     ]
    }
   ],
   "source": [
    "col1, col2 = full_df2.columns, full_df.columns\n",
    "# full_df2.columns[:-3]\n",
    "# common_cols = set(col1).intersection(set(col2))\n",
    "df_combined = full_df2[full_df2.columns[:-3]]\n",
    "df_combined[\"Blast Titles\"] = full_df2['Blast titles']\n",
    "df_combined['Blast Prot Seq'] = full_df2['Blast Prot Seq']\n",
    "df_combined['Go Annotations'] = full_df['Go Annotations']\n",
    "df_combined[\"Involved in Replication\"] = 0\n",
    "# Finally figuring out the ori flag column\n",
    "for i in range(df_combined.shape[0]):\n",
    "    flag_1, flag_2 = full_df.at[i, \"Ori Flag\"], full_df2.at[i, \"Ori Flag\"]\n",
    "\n",
    "    if flag_1 == 1 or flag_2 == 1:\n",
    "        df_combined.at[i, \"Involved in Replication\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1567138e-6d66-4721-901c-f220b8c17da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"/scratch/alopatki_lab/Sharma/summer_project/db_w_blast_uniprot_oriflag.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1918bc3b-07e2-4200-b869-d8482b0081b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis for ppt (13th June 2024)\n",
    "with open(\"/scratch/alopatki_lab/Sharma/summer_project/temp_files/cds_blast_done.pkl\", \"rb\") as file:\n",
    "    # Pickle the dictionary and write it to the file\n",
    "    cds_blast_done = pickle.load(file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a76c079-3380-4b4c-bbdc-8bf0b26f67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], []]\n"
     ]
    }
   ],
   "source": [
    "print(cds_blast_done[\"TEV site\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7bca77d-a61f-4f3f-bc30-b957be78cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEV site, SV40 NLS, HA, nucleoplasmin NLS, OVA peptide, VSV-G tag, enterokinase site, WELQut site, TEE, ssrA tag, minicistron, NLS, 9xHis, tetracysteine tag, Tag-100, myr, HQ tag, -lambda N peptide, c-myc NLS, TVMV site, Genenase(TM) I site, NES, Glu-Glu tag, Spot-Tag, "
     ]
    }
   ],
   "source": [
    "empty_blast = 0\n",
    "for key in cds_blast_done.keys():\n",
    "    if cds_blast_done[key] == [[], []]:\n",
    "        print(key, end = \", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f43b7-fe97-4354-8772-2e8f2a4d0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_anno_keys = []\n",
    "for key in cds_go_annotations.keys():\n",
    "    if cds_go_annotations[key] == None or len(cds_go_annotations[key]) == 0:\n",
    "        empty_anno_keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93a675-142f-44d3-98ee-4326dc69bc56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(len(empty_anno_keys)):\n",
    "    curr_key = empty_anno_keys[i]\n",
    "    print(f\"Current key: {curr_key}\")\n",
    "    uniprot_id = input(\"Uniprot ID for curr_key? Enter -1 if no ID found: \")\n",
    "    if uniprot_id == -1:\n",
    "        cds_go_annotations[curr_key] == []\n",
    "        clear_output(wait = True)\n",
    "    else:\n",
    "        annotations = get_go_annotations(uniprot_id)\n",
    "        cds_go_annotations[curr_key] = annotations\n",
    "        clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff7d46-d48a-44a9-bf8b-fb3bca61a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(cds_go_annotations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794b445-305d-4ac0-a7e6-2ba16a9c0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will psate the code to do blast in here and integrate the uniprot code in it and run it on a small sample dataset\n",
    "# Defing functions we will use \n",
    "\n",
    "def extract_cds(row):\n",
    "    if row[\"Feature Type\"] == \"CDS\":\n",
    "        if row[\"Feature Label\"] in cds_to_keep.keys():\n",
    "            return row[\"Feature Sequence\"]\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def blast_and_get_go_annotations(nucleotide_sequence):\n",
    "    # Perform BlastX search\n",
    "    result_handle = NCBIWWW.qblast(\"blastx\", \"nr\", nucleotide_sequence)\n",
    "    blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    # Get top 10 results and store description and protein sequence\n",
    "    blast_results = {}\n",
    "    for alignment in blast_record.alignments[:10]:\n",
    "        for hsp in alignment.hsps:\n",
    "            blast_results[alignment.title] = {\n",
    "                \"description\": alignment.title,\n",
    "                \"protein_sequence\": hsp.sbjct\n",
    "            }\n",
    "    # print(blast_results)\n",
    "    # Perform GO annotation lookup on UniProt REST API\n",
    "    go_annotations = {}\n",
    "    for protein_sequence in blast_results.values():\n",
    "        # Search UniProt REST API for the protein sequence\n",
    "        uniprot_entries = search_uniprot(protein_sequence[\"protein_sequence\"])\n",
    "        if uniprot_entries:\n",
    "            # Retrieve GO annotations for the UniProt entries\n",
    "            go_terms = get_go_annotations(uniprot_entries)\n",
    "            go_annotations[protein_sequence[\"protein_sequence\"]] = go_terms\n",
    "    # print(go_annotations)\n",
    "    return [blast_results, go_annotations]\n",
    "\n",
    "\n",
    "\n",
    "def search_uniprot(protein_sequence):\n",
    "    \"\"\"\n",
    "    Searches the UniProt REST API for the given protein sequence and returns the matching UniProt entries.\n",
    "    \"\"\"\n",
    "    url = \"https://rest.uniprot.org/align\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"query\": protein_sequence,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"results\", [])\n",
    "    else:\n",
    "        print(f\"Error querying UniProt: {response.status_code} - {response.text}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "# def search_uniprot(protein_sequence):\n",
    "#     \"\"\"\n",
    "#     Searches the UniProt REST API for the given protein sequence and returns the matching UniProt entries.\n",
    "#     \"\"\"\n",
    "#     url = \"https://www.uniprot.org/uniprot/?format=json&query=sequence:{}\".format(protein_sequence)\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         data = response.json()\n",
    "#         return data[\"results\"]\n",
    "#     return []\n",
    "\n",
    "def get_go_annotations(uniprot_entries):\n",
    "    \"\"\"\n",
    "    Retrieves the GO annotations for the given UniProt entries.\n",
    "    \"\"\"\n",
    "    molecular_function = []\n",
    "    biological_process = []\n",
    "    for entry in uniprot_entries:\n",
    "        if \"goTerms\" in entry:\n",
    "            for go_term in entry[\"goTerms\"]:\n",
    "                if go_term[\"category\"] == \"molecular function\":\n",
    "                    molecular_function.append(go_term[\"id\"])\n",
    "                elif go_term[\"category\"] == \"biological process\":\n",
    "                    biological_process.append(go_term[\"id\"])\n",
    "    return {\n",
    "        \"molecular_function\": molecular_function,\n",
    "        \"biological_process\": biological_process\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dca897-86ed-4c11-8b74-380ea3a5a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76553e6d-102c-4868-a9c2-2e03e996dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bioservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3aa4a-ad2f-407c-9cc4-68255ed0731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!help bioservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be1eb8-2f7f-4dbe-94b7-c89ab81b1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "import time\n",
    "\n",
    "def uniprot_blast_search(protein_sequence):\n",
    "    \"\"\"Automates a BLAST search on UniProt and returns the top result.\"\"\"\n",
    "\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"https://www.uniprot.org/blast/\")\n",
    "\n",
    "    try:\n",
    "        # Input protein sequence \n",
    "        sequence_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"sequence-submission-input\"))\n",
    "        )\n",
    "        sequence_input.send_keys(protein_sequence)\n",
    "\n",
    "        # Scroll until the \"BLAST\" button is visible and clickable\n",
    "        submit_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit' and ./span[text()='BLAST']]\"))\n",
    "        )\n",
    "        while True:\n",
    "            try:\n",
    "                submit_button.location_once_scrolled_into_view  # Scroll to the element\n",
    "                if submit_button.is_enabled() and submit_button.is_displayed():\n",
    "                    break  # Exit the loop if the button is clickable\n",
    "            except StaleElementReferenceException:\n",
    "                # Handle cases where the element might be detached during scrolling\n",
    "                submit_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit' and ./span[text()='BLAST']]\"))\n",
    "                )\n",
    "            driver.execute_script(\"window.scrollBy(0, 100);\")  # Scroll down a bit\n",
    "            time.sleep(0.2)  # Small delay for smoother scrolling\n",
    "\n",
    "        # Pause for 4 seconds\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Click the BLAST button\n",
    "        submit_button.click()\n",
    "\n",
    "        # Wait for \"Completed\" link and click \n",
    "        try:\n",
    "            completed_link = WebDriverWait(driver, 600).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//div[@class='card__content']//span[@class='dashboard__body__status']/a\"))\n",
    "            )\n",
    "            completed_link.click()\n",
    "        except TimeoutException:\n",
    "            print(\"Error: BLAST search did not complete within 600 seconds.\")\n",
    "            return None\n",
    "\n",
    "        # Wait for the target link on the new page (adjust timeout if needed)\n",
    "        try:\n",
    "            target_link = WebDriverWait(driver, 30).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//td//span[@class='S2LRp S9Gr5']/a[@class='BqBnJ']\")) \n",
    "            )\n",
    "            target_link.click()\n",
    "\n",
    "            time.sleep(10)  # Adjust as needed\n",
    "\n",
    "            # Scroll to the keywords section\n",
    "            keywords_header = WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h3[@data-article-id='keywords']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", keywords_header)\n",
    "            time.sleep(60)\n",
    "            # Wait for the info-list to be present\n",
    "            info_list = WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h3[@data-article-id='keywords']/following-sibling::ul[@class='info-list']\"))\n",
    "            )\n",
    "\n",
    "            # Extract keywords and values\n",
    "            keyword_dict = {}\n",
    "            for item in info_list.find_elements(By.TAG_NAME, \"li\"):\n",
    "                keyword = item.find_element(By.CLASS_NAME, \"decorated-list-item__title\").text\n",
    "                values = [a.text for a in item.find_elements(By.XPATH, \".//div[@class='decorated-list-item__content']//a\")]\n",
    "                keyword_dict[keyword] = values\n",
    "\n",
    "            # Print or return the dictionary\n",
    "            print(keyword_dict)\n",
    "\n",
    "            time.sleep(60)\n",
    "            return keyword_dict\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Error: Target link, keywords section, or info-list not found on the results page.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "protein_sequence = \"MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAISMSDNTAANLLLTTIGGPKELTAFFHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\"\n",
    "uniprot_blast_search(protein_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330d661-a07a-4d77-aba5-0ea9aaaef9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_uniprot('VTKQEKTALNMARFIRSQTLTLLEKLNELDADEQADICESLHDHADELYRSCLARFGDDGENL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecf8dc-9ece-4e3b-8fb1-9cf8731e79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = full_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc267d-03c2-4628-855e-69679a62a8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq = extract_cds(sample_df.iloc[47])\n",
    "res = blast_and_get_go_annotations(seq)\n",
    "blast_res, uniprot_res = res[0], res[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22906045-2fe9-4bce-8916-b66b4b532f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0755e79-9a17-41de-b6c9-f0290bffe1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Blast\"] = None\n",
    "# full[\"Uniprot\"] = None\n",
    "for i in range(len(full_df)):\n",
    "    print(f\"Currently processing row: {i+1}/{len(full_df)}\")\n",
    "    row = full_df.iloc[i]\n",
    "    seq = extract_cds(row)\n",
    "    if seq == -1:\n",
    "        full_df.iloc[i][\"Blast\"] = None\n",
    "        # sample_df.iloc[i][\"Uniprot\"] = None\n",
    "    else:\n",
    "        full_df.iloc[i][\"Blast\"] = blast_and_get_go_annotations(seq)[0]\n",
    "        print(full_df.iloc[i])\n",
    "        time.sleep(1)\n",
    "    \n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ef0ae-ac38-4379-ab17-81cd9212d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "addgene",
   "language": "python",
   "name": "addgene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
